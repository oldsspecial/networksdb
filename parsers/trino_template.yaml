pipeline:
  name: network_discovery_example
  description: Example pipeline for network discovery data
  version: 1.0.0
  schema_modules: [networksdb]

  stages:
    - id: read_csv
      type: csv_reader
      config:
        path: data/large_test.csv
        encoding: utf-8
        batch_size: 10000

    - id: parse_entities
      type: dict_parser
      input: read_csv
      config:
        error_handling:
          strategy: continue_on_error
          required_entities: []
        mapping:
          imports:
            - network_discovery.yaml

    # Write parsed entities to Trino staging tables
    - id: stage_to_trino
      type: trino_writer
      input: parse_entities
      config:
        connection:
          host: localhost
          port: 8080
          http_scheme: http
          user: trino
          catalog: iceberg
          schema: default
        # Staging table names
        nodes_table: iceberg.testdb.nodes_staging
        relationships_table: iceberg.testdb.relationships_staging
        batch_size: 10000
        # Create tables if they don't exist
        create_tables: true

    # SQL-based deduplication and merge into final tables
    - id: deduplicate_and_merge
      type: sql_insert_dedup
      input: stage_to_trino
      config:
        # Final table names
        target_nodes_table: iceberg.testdb.nodes
        target_relationships_table: iceberg.testdb.relationships
      
        # Create final tables if they don't exist
        create_tables: true
        #node_table_partition: null
        #relationship_table_partition: null